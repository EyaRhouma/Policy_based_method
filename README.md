[//]: # (Image References)

[image1]: https://user-images.githubusercontent.com/10624937/42135605-ba0e5f2c-7d12-11e8-9578-86d74e0976f8.gif "Trained Agent"

[image2]: https://user-images.githubusercontent.com/10624937/42135683-dde5c6f0-7d13-11e8-90b1-8770df3e40cf.gif "Trained Agent"
# Value based method

In this repository we're trying to solve 2 openAI Gym's env using two policy based methods: Hill climbing and Cross-Entropy method

## Hill Climbing

`Hill_Climbing.ipynb` is an implementation of hill climbing with adaptive noise scaling for OpenAI Gym's Cartpole environment.

### Result

![Trained Agent][image2]


## Cross-Entropy Method

`CEM.ipynb` is an implementation of the cross-entropy method for OpenAI Gym's MountainCarContinuous environment.

### Result

![Trained Agent][image1]

## Additionals

For more well explained methods for policy based method here's a good blog:

http://kvfrans.com/simple-algoritms-for-solving-cartpole/

--> corresponding github: https://github.com/kvfrans/openai-cartpole


